
We implemented our $k$-bounded dependent test detection algorithm 
in a prototype tool.\footnote{Available at: \url{http://testisolation.googlecode.com}} 
%written in the form of JUnit 3.X.
The tool is fully-automated and needs only a test suite and the
bounding parameter $k$ as inputs. 
Our
current implementation supports JUnit 3.x tests.
%exhaustively executes every $k$-tuple
%of tests, and compares execution results to identify possible dependence cases. When
%comparing the observed result of a test in an execution order with
%its intended result (corresponding to line 6 in Figure~\ref{fig:dtalgorithm}),
We consider JUnit test results to be the same when the tests either
both pass, or exactly the same exception or assertion violation leads
to test failure.
%if both the observed result and intended result are passing or
%exactly the same exceptions are thrown otherwise. 
The tool creates a fresh JVM for each \testlist, thus, ignoring
external state such as files and OS services, the environment
that the test suites are executed in is always the same $\env_0$.
This ensures that there is no interaction between
different \testlist\ through shared memory.

We used the prototype to verify the dependent tests reported by
users, developers, other researchers, and us, and to find new dependent
tests in the
example programs in Section~\ref{sec:examples} using isolated execution ($k = 1$)
and pairwise execution ($k = 2$).

All the dependent tests reported in Figure~\ref{fig:example-summary},
except for two dependent tests in JodaTime and the dependences in SWT, 
can already be found by isolated execution. Since we could not run the
test suite of SWT, we could not check these dependences with our tool.
During manual bug diagnosis in JodaTime, we identified two test dependences that require
\emph{three} tests to manifest. While these are easy to reproduce, we
did not check that our tool finds them, because the time needed to
run our naive algorithm on JodaTime with $k=3$ is measured in months.

While we believe that most test dependences can be found with small
$k$. This is in part because the set of dependent tests that can be
found with a bound $k$ is always a subset of the set of dependent
tests that can be found with any bound $k' > k$. Additionally, our
intuition and preliminary exploration seem to indicate that small $k$
find many dependences, while larger $k$ do not. However, in principle
it is conceivable
that any number of chain dependences with chains longer than any tried $k$ exist
in all the libraries we analyzed.


%However, due to the computational complexity of the general dependent test
%detection problem, it is difficult to know precisely how many dependent
%tests exist in a test suite. Thus, we do not
%yet have empirical data that shows how many percentages of dependence tests
%our tool can catch. Giving a reasonable estimation
%is one of our future work.

%we do not yet have strong empirical data that shows our algorithm catches X
%percentage or Y of the worst test dependences. It is one of our future work.


% The tool is publicly
% available\footnote{\url{http://testisolation.googlecode.com}}.
% The source code and user manual of our tool is publicly available at:
% \url{http://testisolation.googlecode.com}


% vim:wrap:wm=8:bs=2:expandtab:ts=4:tw=70:
