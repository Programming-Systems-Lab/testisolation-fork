\begin{abstract}

In a unit test suite, all the test cases should be independent:  no test
should affect any other test's result, and running the tests in any order
should produce the same test results.
Test independence is important so that tests behave consistently as intended by the developers.
In addition, techniques such as test selection
and prioritization assume that the tests in a suite are independent.
This paper presents four results related to test dependence.

First, we show that test dependence arises in practice.
We studied \dtnum real-world dependent tests from \repnum
issue tracking systems.
Our study identifies common characteristics of dependent tests.
It shows that test dependence can be hard for programmers to identify.
It also shows the costly consequences of test dependence, such as masking
program faults and leading to spurious bug reports.

Second, we formally define test dependence in terms of
test suites as ordered sequences of tests along with explicit
environments in which these tests are executed.
We formulate the problem
of detecting dependent tests and prove that a useful special
case is NP-complete. 

Third, guided by the study of real-world dependent tests, we propose three
algorithms to detect
dependent tests in a test suite. 

Fourth, we implemented our dependent test detection algorithms
and applied them to \subjnum real-world programs.
Our tool revealed previously-unknown dependent tests
in every subject program we studied, from both human-written
and automatically-generated test suites.

%the follwoing claim might be too strong
%Our tool revealed a large number of previously-unknown dependent tests.
%In our study, on average \todo{xx}\% of the human-written tests are
%dependent and \todo{xx}\% of the automatically-generated tests
%are dependent.

\end{abstract}

\label{dummy-label-for-etags}
