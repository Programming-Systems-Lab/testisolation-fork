%%%this file includes many commented out sentences

%In this paper, we
%show through a set of substantive real-world examples that test dependence arises in practice. 
%that only manifests when a sequence of three tests are run in a specified, non-default order.
%approximates solutions to this problem.

%.  For example, we identify several situations where test dependence masks
%program faults: in these situations, running the test suite in the default order does not expose a fault

%but running the suite in a different order does.  
%We also argue that existing
%tools rarely ``surface'' test dependences in a direct way, making it harder for developers
%to observe them.


%To a lesser degree, we describe how two trends in software testing may interact
%with test dependence: one, downstream testing tools such as selection, prioritization,
%and parallelization are increasingly common, and may assume that the
%suites they take as input have no test dependences; and, two, automated test
%generation tools are becoming more common, and we provide some initial
%evidence that test dependence appears to be orders of magnitude more common
%in automatically-generated test suites than in manually-produced suites.
%

%WE show that, in practice,
%test dependence does occur sometimes and does have grave consequences.
%We further argue, that given the increasing importance of second-order
%testing techniques, such as prioritization and parallelization, which
%are directly affected by test dependence, this topic deserves
%attention from the research community. As a first step, 


%: (a) given the lack of


%Further, considering the increasing importance of
%automated test generation techniques, we wanted to get an impression
%of whether test dependence occurs in automatically generated test
%suites. We applied Randoop to the same
%set of programs and 
%attention to test dependence, reporting solely on potential but
%unrealized dependence, that is, ``false positives'', might be of little value; and
%(b) computational advantages arise from computing manifest rather than
%potential dependence.

%In practice, test suites that are thought to include only independent
%tests but that manifest dependence can cause problems including:
%\begin{itemize}
%\item masking faults in the program that are not exposed in one execution order but that are
%in another order; 
%\item exhibiting unexpected
%results if reordered (for instance, by downstream testing techniques such as
%test selection or prioritization), a likely indication of poor test construction; and,
%\item reporting of spurious bugs.
%% if the tests are intended to be dependent but the dependence
%%is undocumented. \todo{DN}{I'm thinking of removing this bullet from the intro.
%%It's a bit different, in that the test writers understand the dependence, of course.
%%I'm just afraid that it'll increase confusion instead of clarifying things.}
%\end{itemize}

%As an example of the first category, the JodaTime library
%(Section~\ref{sec:jodatime}) defines a complex caching system.  Its
%test suite includes tests that check the rather complicated function that normalizes
%object states into cache keys.
%However, an unexpected test dependence between two tests masks a bug in this code. The default
%test execution order exercises an unintended path for one test because an object is
%already cached due to a previously executed test; the fault is exposed if that object
%is not initially cached, as would happen
%if the two tests
%are executed in the reverse order.
%Examples of the other categories are
%described in Section~\ref{sec:examples}.

%Test suites with unknown dependent tests may also exhibit unexpected
%results if reordered by downstream testing techniques such as
%test selection or prioritization  In addition, undocumented
%but desired test dependence can
%lead to spurious bug reports.

%
%Changing a test suite's execution order can
%increase the potential to change the execution environment for a given test:
%different tests may be executed before that given test, and they may
%produce an environment that may cause the test to have a different result.

%
%It is justified to argue that developers 
%should take the utmost care to initialize their tests correctly and completely. In principle,
%such setup code could be part of each individual test case. Frameworks

%The frameworks provide effective mechanisms for setting test execution
%environments, but they do not ensure that these mechanisms are used properly.
%And the more complex a programs structure
%is, the more likely it is that some initialization of global variables
%will be forgotten. By identifying test dependence
%as a more broadly discussed issue, and by providing algorithms and
%tools for identifying test dependences, we hope to reduce their


%Yet no framework can ensure that these methods are used
%correctly. 
%Since we are most interested in practical issues, we argue that
%developers are as likely to make mistakes when writing tests, as they
%are when writing code. 
%\todo{mark it red to avoid been overlooked}{frequency and their cost.}

%\subsection{Downstream Testing Tools}

%In essence, these tools may have an unstated precondition---''the input
%must have no test dependences''---that may not be checked or satisfied in some cases.
%An alternative would be for the tools to detect and eliminate dependences.
%
%If this selection happened for regression testing, developers may be
%led to investigate only modified and newly added code to find the
%fault. But it is possible that the fault lies
%elsewhere and has not been discovered due to the dependence in the
%test suite. \todo{KM}{I don't buy this. Once you have the failing test, it
%should not be very hard for a reasonable developer to find the real reason
%behind the failure.}

%
%The two fundamental operations that such tools can apply to test
%suites are sub-suite selection, and suite reordering. Our
%formalization in Section~\ref{sec:formalism} and the examples in
%Section~\ref{sec:examples} show that both these operations can
%produce test suites that exhibit manifest dependences, because all
%these operations lead to tests being executed in potentially different
%environments. While there are some differences between selection and
%re-ordering, these are not significant for the following discussion. 
%Therefore, in Section~\ref{sec:related} we consider only
%related work in test prioritization as a representative of this
%entire class of techniques. %, especially due to its concern with reordering.
%

%The value of studying manifest dependence lies in the fact that
%it can impact second
%order techniques, such as test prioritization or parallelization.
%One premise of such techniques is usually that executing tests in any
%order or in parallel will produce the same results. Therefore, we
%consider as test dependence, effects that cause the results of tests
%to differ when they are executed in different environments.
%Such test dependence may arise when the test results rely on a particular
%context that may unexpectedly differ from one execution order to
%another (Figure~\ref{fig:downstream}).  
%For example, if test \code{A} assumes that a global variable has been
%initialized by some other test, executing test \code{A} before those
%tests may cause different test results.
%Conversely, tests are independent when
%they either do not rely on context at all, or assure the correct
%context before executing.



% \todo{KM}{I don't think what this paragraph says is true. I recommend cutting
% it (the above paragraph also contains what it tries to say).} Our examples also
% show extensive use of test infrastructure that can reduce test dependence: in
% JUnit\footnote{\url{http://www.junit.org}}, \code{setUp()} and
% \code{tearDown()} as well as \code{@before} and \code{@after}
% annotations help developers significantly but allowing them to more
% easily establish the execution environment.  However, these and
% related features are mechanisms only and are not intended to, and do
% not, enforce any policies to ensure that developers use the
% mechanisms consistently and effectively.
% 
% Why do some tests allow varying execution environments?  Can't this
% be easily avoided?
% We contend
% that this is for the same reasons that developers still create bugs,
% still don't always initialize program variables, still don't always check
% array lengths before indexing, etc.  By identifying test dependence
% as a more broadly discussed issue, and by providing algorithms and
% tools for identifying test dependences, we hope to reduce their
% frequency and their cost.

%While superficially straightforward, reasoning about test dependence
%%and the potential causes and consequences of test dependence is
%is intricate and non-trivial. We introduce a formalism to help
%understand and reason about test dependence.  The two key aspects
%of the formalism are (a) defining
%test
%suites as ordered sequences of tests and (b) making explicit the
%context in which tests are run. The formalism provides a precise
%basis for defining test dependence, for proving the (NP-hard) complexity
%of determining if a suite can manifest test dependences, and for
%algorithms that can efficiently identify important classes of dependences.
%
%
%may arise due to the context 
%in which tests are
%executed (Section~\ref{sec:formalism} formalizes context). Hence, the
%notion and use of context is the second fundamental part of our
%formalism.


%We raise awareness of the problems caused by the test
%  independence assumption but demonstrating through theory and
%  manifestations of test dependence that the consequences can be
%  severe. 
%  \item We define a formalism to reason about test suites as sequences
%  and show how dependences arise in theory and practice.
%  \item We lay a foundation for efficient heuristic algorithms to
%  detect dependences in existing test suites and show with some
%  examples that heuristics rather than exhaustive algorithms already
%  have signigificant benefits.


%\todo{JW}{I couldn't fit this into the rewritten intro. I might like
%to use in in Sec 4 or 5}
%The two ways
%  of altering context that we address here are \emph{isolation} and
%  \emph{ordering}.  By isolation, we mean executing each test in a
%  test suite separately: for example, in a different instance of JUnit
%  or in a different virtual machine.  This isolates, and may provide a
%  different context for a test, by ensuring that the initial context
%  is reinitialized for each test.  In contrast, most conventional
%  approaches execute tests in a sequence in the same context, giving
%  (for example) the second test an execution context that can in
%  principle depend in part on how the first test may have modified the
%  context.  By ordering (which as we show in
%  Section~\ref{sec:formalism} is strictly more general than
%  isolation), we mean that the sequence in which tests in a test suite
%  are executed can be varied.  A different ordering of test execution
%  can cause a given test to execute in a different context and,
%  perhaps, provide a different result.

%\todo{DN}{I think we will need to go over the paper later on in the process to make
%really sure we are consistent about test dependence definitions and our writing.
%If I am clear, we define dependence between two tests; we often (informally?)
%talk about a suite with dependence(s).}
%\todo{JW}{Informally, you are correct. I'll make sure to clarify this
%in the text}
%\todo{DN}{We are also inconsistency about ``dependence'' vs. ``dependency'' vs. ``dependencies'' and
%such.  Probably not a big deal, but if we have time...}
%\todo{DN}{General comment about the intuition below -- it's too long now, which makes it less intuitive.}


%As shown in Section~\ref{sec:examples}, most real examples of test dependence we have seen to date relate
%to mistakes in the initialization of test environments.
%\footnote{Test frameworks such as JUnit 
%provide \emph{mechanisms}, such as \code{@Before} and \code{@After} annotations, to help developers more easily
%establish execution conditions.  They are not intended to, and
%do not, \emph{enforce} any policies
%to ensure that developers use these mechanisms consistently and effectively.}

%Consider the two examples (Figure~\ref{fig:dep_examples})
%of the basic
%way dependencies between tests arise in practice. \code{test2} checks
%the value of a variable that has been assigned elsewhere. If the tests
%are executed in the order \code{test1, test2}, both tests will pass (assuming \code{test1} does not
%change the value of \code{a} after the initial assignment),
%while running \code{test2} first will make it fail.  To determine
%potential test dependences would require an analysis of the read/write
%behavior of the tests (for example, under what conditions, if any, does \code{test1} change the value of \code{a}?); such analyses are well-known to be
%imprecise and/or incomplete.    


% to cleanly set all execution conditions for each test
%case. Methods marked with the
%annotations \code{@Before} and \code{@After} are executed before and
%after each test case and are intended to initialize and clean the
%execution conditions for each test case.
%}

%When not all state in the environment is cleanly initialized, test
%dependences can arise, because then the actual state when a test case
%executes can change depending on, for example,


%Very informally, dependence between tests, like the one described above, arises when test cases do not include all% relevant execution conditions.
%In particular, when they compute their result based on a shared global data, and this shared global data (we call it \emph{environment}) is initialized external to the test case.

%\todo{DN}{I'd love to see if we can reduce or eliminate the discussion of JUnit here.  The following
%paragraph, for example, seems confusing in the following sense: if junit has this, why is there a
%dependence problem?  This is obvious to us, but I don't want people thinking about that here. Moved it
%to a footnote -- before/after -- and rewrote a little}
%

%In this section we first give an intuition what causes test
%dependence and what its consequence may be. Then we formally define
%our notion of test dependence, and lastly we demonstrate how these
%notions lead to the \emph{test dependence detection} problem, and how
%we can solve it.

%\todo{JW}{Find a better section heading or remove the heading}
%\subsection{Intuition}



%
%rely on executing in a
%particular context, for example some test may assume that global variables have
%been initialized to specific values, without confirming the expected
%context before they execute. 

%\todo{DN}{I'm at present inclined to move the example to here, but the test structure/results
%text.  That is, use the example to describe those rather than vice versa.  Sort of like: (a) here
%is a simple example; (b) note that a complete analysis of test dependence would require a full
%analysis of the code in test1 to determine possible values for a; (c) instead of considering that
%complicated analysis that would describe the potential for dependence, we use the test oracles/results
%to represent the outcome of the execution, in a given environment.  Or possibly move the
%potential/actual text up instead, and describe how we address it, then the example?}




%Consider the two examples in Fig.~\ref{fig:dep_examples}. The example
%in Fig.~\ref{fig:dep_examples:direct} shows the most basic
%way dependencies between tests arise in practice. \code{test2} checks
%the value of a variable that has been assigned elsewhere. If the tests
%are executed in the order \code{test1, test2}, both tests will pass,
%while running \code{test2} first will make it fail.

%

%\todo{SZ}{for example (b), perphas we can make it more clearer as
%follows:  test1 \{a++\}, test2\{a++\}, ..., testn \{assert a == n-1\}}
%
%\todo{JW}{While this is also a dependence, it does \emph{not} enforce
%any particular order on the first n-1 tests.}
%
%\todo{KM}{I second Jochen. We discussed this quite a bit with him and I think
%he came up with the most readable and easiest example that forces the execution
%of only t1-t1-\ldots-tn to pass and all other orders to fail.}

%Test dependences arise when tests rely on state that is generated
%by other tests. %CLI is a case in point. 
%Most examples we found are quite direct dependecies on
%global variables, where one test implicitly relies on a global variable to be in
%a certain state before executing the sequence of methods to be tested. 
%At a more abstract level, we can think of test dependence as
%read/write conflicts between different transactions. Each test reads
%and writes variables. If a test implicitly assumes a variable to be in
%a particular state, but does not ensure this state before it executes,
%the test may fail.
%\todo{JW}{
%Thinking of the causes for test dependences as read/write conflicts
%might go far. Intuitively, I think the cases that cause parallel
%transactions to abort are the \emph{good} cases for us (because each
%test ensures that it has written the values it needs). All other cases
%seem potentially hazardous. I'll dig into this tomorrow}


%This is in strong contrast to most
%existing work that considers test suites in general as sets, and thus
%ignores the ordering aspect that is important here.
%Informally, a test dependence arises when the results of executing
%test suites in different orders differ. The following formal
%definitions make our notion of test dependence precise.
%\todo{DN}{I took out the ``informally'' sentence or so here, since we've done that
%already a number of times, and now we're going formal!}


%So while manifest dependences can reveal such a problem, the
%underlying fault is in the program and affects first-order testing and
%use of the program.
%In its simplest form, masking occurs when parts of a program or tests assume that
%global state has correctly been initialized before these parts can
%ever execute. When this assumption is incorrect, because
%initialization is not implemented correctly, the interactions of
%different parts of the program might jointly modify the global state
%in ways that lead to intricate and subtle faults.
